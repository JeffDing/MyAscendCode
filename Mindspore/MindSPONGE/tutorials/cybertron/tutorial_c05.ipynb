{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2022 @ Shenzhen Bay Laboratory & Peking University & Huawei Technologies Co., Ltd\n",
    "\n",
    "This code is a part of Cybertron package.\n",
    "\n",
    "The Cybertron is open-source software based on the AI-framework:\n",
    "MindSpore (https://www.mindspore.cn/)\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "Cybertron tutorial 05: Multi-task with multiple readouts (example 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import nn\n",
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "from cybertron import Cybertron\n",
    "from cybertron import MolCT\n",
    "from cybertron import AtomwiseReadout\n",
    "from cybertron.train import MAE, MLoss\n",
    "from cybertron.train import WithLabelLossCell, WithLabelEvalCell\n",
    "from cybertron.train import TrainMonitor\n",
    "from cybertron.train import TransformerLR\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = sys.path[0] + '/dataset_qm9_normed_'\n",
    "train_file = data_name + 'trainset_1024.npz'\n",
    "valid_file = data_name + 'validset_128.npz'\n",
    "\n",
    "train_data = np.load(train_file)\n",
    "valid_data = np.load(valid_file)\n",
    "\n",
    "idx = [7, 8, 9, 10]  # U0,U,G,H\n",
    "\n",
    "num_atom = int(train_data['num_atoms'])\n",
    "scale = Tensor(train_data['scale'][idx], ms.float32)\n",
    "shift = Tensor(train_data['shift'][idx], ms.float32)\n",
    "ref = Tensor(train_data['type_ref'][:, idx], ms.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = MolCT(\n",
    "    cutoff=1,\n",
    "    n_interaction=3,\n",
    "    dim_feature=128,\n",
    "    n_heads=8,\n",
    "    activation='swish',\n",
    "    max_cycles=1,\n",
    "    length_unit='nm',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout0 = AtomwiseReadout(mod, dim_output=1)\n",
    "readout1 = AtomwiseReadout(mod, dim_output=1)\n",
    "readout2 = AtomwiseReadout(mod, dim_output=1)\n",
    "readout3 = AtomwiseReadout(mod, dim_output=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Cybertron(mod, readout=[\n",
    "    readout0, readout1, readout2, readout3], num_atoms=num_atom, length_unit='nm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cybertron<\n",
       "  (model): MolCT<\n",
       "    (activation): Swish<\n",
       "      (sigmoid): Sigmoid<>\n",
       "      >\n",
       "    (atom_embedding): Embedding<vocab_size=64, embedding_size=128, use_one_hot=True, embedding_table=Parameter (name=model.atom_embedding.embedding_table, shape=(64, 128), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "    (cutoff_fn): SmoothCutoff<>\n",
       "    (rbf): LogGaussianBasis<>\n",
       "    (dis_filter): ResFilter<\n",
       "      (linear): Dense<input_channels=64, output_channels=128, has_bias=True>\n",
       "      (residual): Residual<\n",
       "        (nonlinear): MLP<\n",
       "          (mlp): SequentialCell<\n",
       "            (0): Dense<\n",
       "              input_channels=128, output_channels=128, has_bias=True, activation=Swish<>\n",
       "              (activation): Swish<\n",
       "                (sigmoid): Sigmoid<>\n",
       "                >\n",
       "              >\n",
       "            (1): Dense<input_channels=128, output_channels=128, has_bias=True>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (interactions): CellList<\n",
       "      (0): NeuralInteractionUnit<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (dis_filter): ResFilter<\n",
       "          (linear): Dense<input_channels=64, output_channels=128, has_bias=True>\n",
       "          (residual): Residual<\n",
       "            (nonlinear): MLP<\n",
       "              (mlp): SequentialCell<\n",
       "                (0): Dense<\n",
       "                  input_channels=128, output_channels=128, has_bias=True, activation=Swish<>\n",
       "                  (activation): Swish<\n",
       "                    (sigmoid): Sigmoid<>\n",
       "                    >\n",
       "                  >\n",
       "                (1): Dense<input_channels=128, output_channels=128, has_bias=True>\n",
       "                >\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        (positional_embedding): PositionalEmbedding<\n",
       "          (norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.0.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.0.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (x_norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.0.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.0.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (g_norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.0.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.0.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (x2q): Dense<input_channels=128, output_channels=128>\n",
       "          (x2k): Dense<input_channels=128, output_channels=128>\n",
       "          (x2v): Dense<input_channels=128, output_channels=128>\n",
       "          >\n",
       "        (multi_head_attention): MultiheadAttention<\n",
       "          (output): Dense<input_channels=128, output_channels=128>\n",
       "          (softmax_with_mask): SoftmaxWithMask<>\n",
       "          >\n",
       "        >\n",
       "      (1): NeuralInteractionUnit<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (dis_filter): ResFilter<\n",
       "          (linear): Dense<input_channels=64, output_channels=128, has_bias=True>\n",
       "          (residual): Residual<\n",
       "            (nonlinear): MLP<\n",
       "              (mlp): SequentialCell<\n",
       "                (0): Dense<\n",
       "                  input_channels=128, output_channels=128, has_bias=True, activation=Swish<>\n",
       "                  (activation): Swish<\n",
       "                    (sigmoid): Sigmoid<>\n",
       "                    >\n",
       "                  >\n",
       "                (1): Dense<input_channels=128, output_channels=128, has_bias=True>\n",
       "                >\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        (positional_embedding): PositionalEmbedding<\n",
       "          (norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.1.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.1.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (x_norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.1.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.1.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (g_norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.1.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.1.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (x2q): Dense<input_channels=128, output_channels=128>\n",
       "          (x2k): Dense<input_channels=128, output_channels=128>\n",
       "          (x2v): Dense<input_channels=128, output_channels=128>\n",
       "          >\n",
       "        (multi_head_attention): MultiheadAttention<\n",
       "          (output): Dense<input_channels=128, output_channels=128>\n",
       "          (softmax_with_mask): SoftmaxWithMask<>\n",
       "          >\n",
       "        >\n",
       "      (2): NeuralInteractionUnit<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (dis_filter): ResFilter<\n",
       "          (linear): Dense<input_channels=64, output_channels=128, has_bias=True>\n",
       "          (residual): Residual<\n",
       "            (nonlinear): MLP<\n",
       "              (mlp): SequentialCell<\n",
       "                (0): Dense<\n",
       "                  input_channels=128, output_channels=128, has_bias=True, activation=Swish<>\n",
       "                  (activation): Swish<\n",
       "                    (sigmoid): Sigmoid<>\n",
       "                    >\n",
       "                  >\n",
       "                (1): Dense<input_channels=128, output_channels=128, has_bias=True>\n",
       "                >\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        (positional_embedding): PositionalEmbedding<\n",
       "          (norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.2.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.2.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (x_norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.2.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.2.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (g_norm): LayerNorm<normalized_shape=(128,), begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.interactions.2.positional_embedding.norm.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.interactions.2.positional_embedding.norm.beta, shape=(128,), dtype=Float32, requires_grad=True)>\n",
       "          (x2q): Dense<input_channels=128, output_channels=128>\n",
       "          (x2k): Dense<input_channels=128, output_channels=128>\n",
       "          (x2v): Dense<input_channels=128, output_channels=128>\n",
       "          >\n",
       "        (multi_head_attention): MultiheadAttention<\n",
       "          (output): Dense<input_channels=128, output_channels=128>\n",
       "          (softmax_with_mask): SoftmaxWithMask<>\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    >\n",
       "  (activation): Swish<\n",
       "    (sigmoid): Sigmoid<>\n",
       "    >\n",
       "  (readout): CellList<\n",
       "    (0): AtomwiseReadout<\n",
       "      (activation): Swish<\n",
       "        (sigmoid): Sigmoid<>\n",
       "        >\n",
       "      (decoder): HalveDecoder<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (output): MLP<\n",
       "          (mlp): SequentialCell<\n",
       "            (0): Dense<\n",
       "              input_channels=128, output_channels=64, has_bias=True, activation=Swish<>\n",
       "              (activation): Swish<\n",
       "                (sigmoid): Sigmoid<>\n",
       "                >\n",
       "              >\n",
       "            (1): Dense<input_channels=64, output_channels=1, has_bias=True>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      (aggregator): TensorSummation<>\n",
       "      >\n",
       "    (1): AtomwiseReadout<\n",
       "      (activation): Swish<\n",
       "        (sigmoid): Sigmoid<>\n",
       "        >\n",
       "      (decoder): HalveDecoder<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (output): MLP<\n",
       "          (mlp): SequentialCell<\n",
       "            (0): Dense<\n",
       "              input_channels=128, output_channels=64, has_bias=True, activation=Swish<>\n",
       "              (activation): Swish<\n",
       "                (sigmoid): Sigmoid<>\n",
       "                >\n",
       "              >\n",
       "            (1): Dense<input_channels=64, output_channels=1, has_bias=True>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      (aggregator): TensorSummation<>\n",
       "      >\n",
       "    (2): AtomwiseReadout<\n",
       "      (activation): Swish<\n",
       "        (sigmoid): Sigmoid<>\n",
       "        >\n",
       "      (decoder): HalveDecoder<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (output): MLP<\n",
       "          (mlp): SequentialCell<\n",
       "            (0): Dense<\n",
       "              input_channels=128, output_channels=64, has_bias=True, activation=Swish<>\n",
       "              (activation): Swish<\n",
       "                (sigmoid): Sigmoid<>\n",
       "                >\n",
       "              >\n",
       "            (1): Dense<input_channels=64, output_channels=1, has_bias=True>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      (aggregator): TensorSummation<>\n",
       "      >\n",
       "    (3): AtomwiseReadout<\n",
       "      (activation): Swish<\n",
       "        (sigmoid): Sigmoid<>\n",
       "        >\n",
       "      (decoder): HalveDecoder<\n",
       "        (activation): Swish<\n",
       "          (sigmoid): Sigmoid<>\n",
       "          >\n",
       "        (output): MLP<\n",
       "          (mlp): SequentialCell<\n",
       "            (0): Dense<\n",
       "              input_channels=128, output_channels=64, has_bias=True, activation=Swish<>\n",
       "              (activation): Swish<\n",
       "                (sigmoid): Sigmoid<>\n",
       "                >\n",
       "              >\n",
       "            (1): Dense<input_channels=64, output_channels=1, has_bias=True>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      (aggregator): TensorSummation<>\n",
       "      >\n",
       "    >\n",
       "  (fc_neighbours): FullConnectNeighbours<>\n",
       "  (distances): IndexDistances<\n",
       "    (get_vector): GetVector<>\n",
       "    (norm_last_dim): Norm<axis=-1, keep_dims=False>\n",
       "    >\n",
       "  >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.set_scaleshift([1, 1, 1], 0, readout_id=[0, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cybertron Engine, Ride-on!\n",
      "--------------------------------------------------------------------------------\n",
      "    Length unit: nm\n",
      "    Input unit scale: 1\n",
      "--------------------------------------------------------------------------------\n",
      "    Deep molecular model:  MolCT\n",
      "--------------------------------------------------------------------------------\n",
      "       Length unit: nm\n",
      "       Atom embedding size: 64\n",
      "       Cutoff distance: 1.0 nm\n",
      "       Radical basis function (RBF): LogGaussianBasis\n",
      "          Minimum distance: 0.04 nm\n",
      "          Maximum distance: 1.0 nm\n",
      "          Reference distance: 1.0 nm\n",
      "          Log Gaussian begin: -3.218876\n",
      "          Log Gaussian end: 0.006724119\n",
      "          Interval for log Gaussian: 0.0512\n",
      "          Sigma for log gaussian: 0.3\n",
      "          Number of basis functions: 64\n",
      "          Rescale the range of RBF to (-1,1).\n",
      "       Calculate distance: Yes\n",
      "       Calculate bond: No\n",
      "       Feature dimension: 128\n",
      "--------------------------------------------------------------------------------\n",
      "       Using 3 independent interaction layers:\n",
      "--------------------------------------------------------------------------------\n",
      "       0. Neural Interaction Unit\n",
      "          Feature dimension: 128\n",
      "          Activation function: Swish\n",
      "          Encoding distance: Yes\n",
      "          Encoding bond: No\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "--------------------------------------------------------------------------------\n",
      "       1. Neural Interaction Unit\n",
      "          Feature dimension: 128\n",
      "          Activation function: Swish\n",
      "          Encoding distance: Yes\n",
      "          Encoding bond: No\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "--------------------------------------------------------------------------------\n",
      "       2. Neural Interaction Unit\n",
      "          Feature dimension: 128\n",
      "          Activation function: Swish\n",
      "          Encoding distance: Yes\n",
      "          Encoding bond: No\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "--------------------------------------------------------------------------------\n",
      "    With 4 readout networks: \n",
      "--------------------------------------------------------------------------------\n",
      "    0. AtomwiseReadout\n",
      "       Activation function: Swish\n",
      "       Decoder: HalveDecoder\n",
      "       Aggregator: TensorSummation\n",
      "       Representation dimension: 128\n",
      "       Readout dimension: 1\n",
      "       Scale: [1.]\n",
      "       Shift: [0.]\n",
      "       Scaleshift mode: Atomwise\n",
      "       Reference value for atom types: None\n",
      "       Output unit: None\n",
      "       Reduce axis: -2\n",
      "--------------------------------------------------------------------------------\n",
      "    1. AtomwiseReadout\n",
      "       Activation function: Swish\n",
      "       Decoder: HalveDecoder\n",
      "       Aggregator: TensorSummation\n",
      "       Representation dimension: 128\n",
      "       Readout dimension: 1\n",
      "       Scale: [1.]\n",
      "       Shift: [0.]\n",
      "       Scaleshift mode: Atomwise\n",
      "       Reference value for atom types: None\n",
      "       Output unit: None\n",
      "       Reduce axis: -2\n",
      "--------------------------------------------------------------------------------\n",
      "    2. AtomwiseReadout\n",
      "       Activation function: Swish\n",
      "       Decoder: HalveDecoder\n",
      "       Aggregator: TensorSummation\n",
      "       Representation dimension: 128\n",
      "       Readout dimension: 1\n",
      "       Scale: 1.0\n",
      "       Shift: 0.0\n",
      "       Scaleshift mode: Atomwise\n",
      "       Reference value for atom types: None\n",
      "       Output unit: None\n",
      "       Reduce axis: -2\n",
      "--------------------------------------------------------------------------------\n",
      "    3. AtomwiseReadout\n",
      "       Activation function: Swish\n",
      "       Decoder: HalveDecoder\n",
      "       Aggregator: TensorSummation\n",
      "       Representation dimension: 128\n",
      "       Readout dimension: 1\n",
      "       Scale: [1.]\n",
      "       Shift: [0.]\n",
      "       Scaleshift mode: Atomwise\n",
      "       Reference value for atom types: None\n",
      "       Output unit: None\n",
      "       Reduce axis: -2\n",
      "--------------------------------------------------------------------------------\n",
      "    Output dimension: [1 1 1 1]\n",
      "    Total output dimension: 4\n",
      "    Output unit for Cybertron: None\n",
      "    Output unit scale: [1. 1. 1. 1.]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "net.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model.atom_embedding.embedding_table (64, 128)\n",
      "1 model.dis_filter.linear.weight (128, 64)\n",
      "2 model.dis_filter.linear.bias (128,)\n",
      "3 model.dis_filter.residual.nonlinear.mlp.0.weight (128, 128)\n",
      "4 model.dis_filter.residual.nonlinear.mlp.0.bias (128,)\n",
      "5 model.dis_filter.residual.nonlinear.mlp.1.weight (128, 128)\n",
      "6 model.dis_filter.residual.nonlinear.mlp.1.bias (128,)\n",
      "7 model.interactions.0.positional_embedding.norm.gamma (128,)\n",
      "8 model.interactions.0.positional_embedding.norm.beta (128,)\n",
      "9 model.interactions.0.positional_embedding.x2q.weight (128, 128)\n",
      "10 model.interactions.0.positional_embedding.x2k.weight (128, 128)\n",
      "11 model.interactions.0.positional_embedding.x2v.weight (128, 128)\n",
      "12 model.interactions.0.multi_head_attention.output.weight (128, 128)\n",
      "13 model.interactions.1.positional_embedding.norm.gamma (128,)\n",
      "14 model.interactions.1.positional_embedding.norm.beta (128,)\n",
      "15 model.interactions.1.positional_embedding.x2q.weight (128, 128)\n",
      "16 model.interactions.1.positional_embedding.x2k.weight (128, 128)\n",
      "17 model.interactions.1.positional_embedding.x2v.weight (128, 128)\n",
      "18 model.interactions.1.multi_head_attention.output.weight (128, 128)\n",
      "19 model.interactions.2.positional_embedding.norm.gamma (128,)\n",
      "20 model.interactions.2.positional_embedding.norm.beta (128,)\n",
      "21 model.interactions.2.positional_embedding.x2q.weight (128, 128)\n",
      "22 model.interactions.2.positional_embedding.x2k.weight (128, 128)\n",
      "23 model.interactions.2.positional_embedding.x2v.weight (128, 128)\n",
      "24 model.interactions.2.multi_head_attention.output.weight (128, 128)\n",
      "25 readout.0.decoder.output.mlp.0.weight (64, 128)\n",
      "26 readout.0.decoder.output.mlp.0.bias (64,)\n",
      "27 readout.0.decoder.output.mlp.1.weight (1, 64)\n",
      "28 readout.0.decoder.output.mlp.1.bias (1,)\n",
      "29 readout.1.decoder.output.mlp.0.weight (64, 128)\n",
      "30 readout.1.decoder.output.mlp.0.bias (64,)\n",
      "31 readout.1.decoder.output.mlp.1.weight (1, 64)\n",
      "32 readout.1.decoder.output.mlp.1.bias (1,)\n",
      "33 readout.2.decoder.output.mlp.0.weight (64, 128)\n",
      "34 readout.2.decoder.output.mlp.0.bias (64,)\n",
      "35 readout.2.decoder.output.mlp.1.weight (1, 64)\n",
      "36 readout.2.decoder.output.mlp.1.bias (1,)\n",
      "37 readout.3.decoder.output.mlp.0.weight (64, 128)\n",
      "38 readout.3.decoder.output.mlp.0.bias (64,)\n",
      "39 readout.3.decoder.output.mlp.1.weight (1, 64)\n",
      "40 readout.3.decoder.output.mlp.1.bias (1,)\n",
      "Total parameters:  280196\n"
     ]
    }
   ],
   "source": [
    "tot_params = 0\n",
    "for i, param in enumerate(net.get_parameters()):\n",
    "    tot_params += param.size\n",
    "    print(i, param.name, param.shape)\n",
    "print('Total parameters: ', tot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 8\n",
    "repeat_time = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds.NumpySlicesDataset(\n",
    "    {'R': train_data['R'], 'Z': train_data['Z'], 'E': train_data['E'][:, idx]}, shuffle=True)\n",
    "ds_train = ds_train.batch(batch_size, drop_remainder=True)\n",
    "ds_train = ds_train.repeat(repeat_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid = ds.NumpySlicesDataset(\n",
    "    {'R': valid_data['R'], 'Z': valid_data['Z'], 'E': valid_data['E'][:, idx]}, shuffle=False)\n",
    "ds_valid = ds_valid.batch(128)\n",
    "ds_valid = ds_valid.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WithLabelLossCell with input type: RZE\n",
      "WithLabelEvalCell with input type: RZE\n",
      "   with scaleshift for training and evaluate dataset:\n",
      "   Output.            Scale           Shift        Mode\n",
      "   0:        1.824854e+01   -4.094204e+02    Atomwise\n",
      "   1:        1.818079e+01   -4.118893e+02    Atomwise\n",
      "   2:        1.816252e+01   -4.142276e+02    Atomwise\n",
      "   3:        1.807273e+01   -3.811549e+02    Atomwise\n",
      "   with reference value for atom types:\n",
      "   Type     Label0    Label1    Label2    Label3\n",
      "   0:        0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "   1:       -1.31e+03 -1.31e+03 -1.31e+03 -1.34e+03\n",
      "   2:        0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "   3:        0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "   4:        0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "   5:        0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "   6:       -9.94e+04 -9.94e+04 -9.94e+04 -9.94e+04\n",
      "   7:       -1.43e+05 -1.43e+05 -1.43e+05 -1.43e+05\n",
      "   8:       -1.97e+05 -1.97e+05 -1.97e+05 -1.97e+05\n",
      "   9:       -2.62e+05 -2.62e+05 -2.62e+05 -2.62e+05\n"
     ]
    }
   ],
   "source": [
    "loss_network = WithLabelLossCell('RZE', net, nn.MAELoss())\n",
    "eval_network = WithLabelEvalCell('RZE', net, nn.MAELoss(), scale=scale, shift=shift, type_ref=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = TransformerLR(learning_rate=1., warmup_steps=4000, dimension=128)\n",
    "optim = nn.Adam(params=net.trainable_params(), learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mae = 'EvalMAE'\n",
    "atom_mae = 'AtomMAE'\n",
    "eval_loss = 'Evalloss'\n",
    "model = Model(loss_network, optimizer=optim, eval_network=eval_network,\n",
    "              metrics={eval_mae: MAE([1, 2], reduce_all_dims=False),\n",
    "                       atom_mae: MAE([1, 2, 3], reduce_all_dims=False, averaged_by_atoms=True),\n",
    "                       eval_loss: MLoss(0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'Tutorial_C05'\n",
    "outname = outdir + '_' + net.model_name\n",
    "record_cb = TrainMonitor(model, outname, per_step=16, avg_steps=16,\n",
    "                         directory=outdir, eval_dataset=ds_valid, best_ckpt_metrics=eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ck = CheckpointConfig(save_checkpoint_steps=32, keep_checkpoint_max=64, append_info=[net.hyper_param])\n",
    "ckpoint_cb = ModelCheckpoint(prefix=outname, directory=outdir, config=config_ck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1253:140223696144192,MainProcess):2022-08-15-14:45:55.506.453 [mindspore/train/model.py:1077] For TrainMonitor callback, {'step_end', 'epoch_end', 'begin'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "Epoch: 1, Step: 16, Learning_rate: 5.2407836e-06, Last_Loss: 19.395395, Avg_loss: 21.205819964408875, EvalMAE: [257.5835  418.14697 250.38379 429.02197], AtomMAE: [15.616847 22.557291 14.756067 23.10646 ], Evalloss: 18.659881591796875\n",
      "Epoch: 1, Step: 32, Learning_rate: 1.0830951e-05, Last_Loss: 14.9859495, Avg_loss: 17.64548945426941, EvalMAE: [221.84961 307.86963 249.17139 282.61328], AtomMAE: [13.346801 16.887314 14.854854 15.581348], Evalloss: 14.611848831176758\n",
      "Epoch: 2, Step: 48, Learning_rate: 1.6421121e-05, Last_Loss: 13.037827, Avg_loss: 13.64117807149887, EvalMAE: [208.90576 201.53906 243.19678 201.6792 ], AtomMAE: [12.348916 11.820057 14.442875 11.936196], Evalloss: 11.770626068115234\n",
      "Epoch: 2, Step: 64, Learning_rate: 2.2011289e-05, Last_Loss: 13.914287, Avg_loss: 12.89821195602417, EvalMAE: [201.92383 208.63525 236.3628  203.8833 ], AtomMAE: [11.968511 12.624997 14.046536 12.166735], Evalloss: 11.70896053314209\n",
      "Epoch: 3, Step: 80, Learning_rate: 2.760146e-05, Last_Loss: 12.461341, Avg_loss: 12.243313431739807, EvalMAE: [193.60254 187.64258 224.79932 185.67822], AtomMAE: [11.3897915 11.122384  13.24114   10.862167 ], Evalloss: 10.89535140991211\n",
      "Epoch: 3, Step: 96, Learning_rate: 3.3191627e-05, Last_Loss: 10.2659645, Avg_loss: 11.527476847171783, EvalMAE: [191.35254 181.03125 220.58936 176.51904], AtomMAE: [11.436158 10.861633 13.122481 10.473261], Evalloss: 10.589089393615723\n",
      "Epoch: 4, Step: 112, Learning_rate: 3.8781796e-05, Last_Loss: 10.914782, Avg_loss: 11.110305428504944, EvalMAE: [168.4331  167.49414 197.08643 158.50244], AtomMAE: [ 9.97696    9.9524355 11.651195   9.363894 ], Evalloss: 9.516019821166992\n",
      "Epoch: 4, Step: 128, Learning_rate: 4.437197e-05, Last_Loss: 10.353494, Avg_loss: 9.60867354273796, EvalMAE: [155.74414 155.65869 173.80664 137.26318], AtomMAE: [ 9.148278  9.31072  10.159841  8.066962], Evalloss: 8.565260887145996\n",
      "Epoch: 5, Step: 144, Learning_rate: 4.9962135e-05, Last_Loss: 6.334096, Avg_loss: 8.390184044837952, EvalMAE: [134.44775  136.58252  148.67041  114.677246], AtomMAE: [7.9788795 8.145045  8.747653  6.789778 ], Evalloss: 7.35273551940918\n",
      "Epoch: 5, Step: 160, Learning_rate: 5.5552304e-05, Last_Loss: 6.9538536, Avg_loss: 7.753217339515686, EvalMAE: [133.42969 115.26953 152.65869 131.16943], AtomMAE: [7.8850904 6.8454685 8.904019  7.7182226], Evalloss: 7.328780174255371\n",
      "Epoch: 6, Step: 176, Learning_rate: 6.114247e-05, Last_Loss: 6.3124695, Avg_loss: 6.2006212174892426, EvalMAE: [ 98.18994  93.90137 100.12793  82.5459 ], AtomMAE: [5.8980675 5.588712  5.957704  4.963455 ], Evalloss: 5.156490325927734\n",
      "Epoch: 6, Step: 192, Learning_rate: 6.6732646e-05, Last_Loss: 3.6112075, Avg_loss: 5.049237012863159, EvalMAE: [85.04297 80.95557 82.51709 79.75488], AtomMAE: [5.1222334 4.820774  4.915237  4.7640924], Evalloss: 4.517235279083252\n",
      "Epoch: 7, Step: 208, Learning_rate: 7.2322815e-05, Last_Loss: 3.8891172, Avg_loss: 4.780360221862793, EvalMAE: [83.89111  81.29932  82.11621  78.592285], AtomMAE: [5.0350866 4.824021  4.876273  4.7029376], Evalloss: 4.4845476150512695\n",
      "Epoch: 7, Step: 224, Learning_rate: 7.791298e-05, Last_Loss: 4.054516, Avg_loss: 4.4533820897340775, EvalMAE: [89.163574 80.46289  77.79541  78.214355], AtomMAE: [5.2530804 4.763499  4.611384  4.646263 ], Evalloss: 4.480726718902588\n",
      "Epoch: 8, Step: 240, Learning_rate: 8.3503146e-05, Last_Loss: 4.0290194, Avg_loss: 4.800688445568085, EvalMAE: [76.29346 76.44092 73.      71.60303], AtomMAE: [4.591103  4.550675  4.3449974 4.310497 ], Evalloss: 4.0916595458984375\n",
      "Epoch: 8, Step: 256, Learning_rate: 8.9093315e-05, Last_Loss: 3.565638, Avg_loss: 4.104118585586548, EvalMAE: [72.92627  82.140625 70.91943  69.773926], AtomMAE: [4.3791285 4.8450174 4.2394834 4.214404 ], Evalloss: 4.069872856140137\n",
      "Training Fininshed!\n",
      "Training Time: 00:00:33\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training ...\")\n",
    "beg_time = time.time()\n",
    "model.train(n_epoch, ds_train, callbacks=[record_cb, ckpoint_cb], dataset_sink_mode=False)\n",
    "end_time = time.time()\n",
    "used_time = end_time - beg_time\n",
    "m, s = divmod(used_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Training Fininshed!\")\n",
    "print(\"Training Time: %02d:%02d:%02d\" % (h, m, s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2496ecc683137a232cae2452fbbdd53dab340598b6e499c8995be760f3a431b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
