{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64deb4d-3c42-439e-bc3c-47e600085fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624a40e7-de43-4c51-8e2e-d2eea73ceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindsponge import Sponge\n",
    "from mindsponge import ForceField\n",
    "from mindsponge.optimizer import SteepestDescent\n",
    "from mindsponge.control import VelocityVerlet\n",
    "from mindsponge.callback import WriteH5MD, RunInfo\n",
    "from mindsponge.control import Langevin\n",
    "from mindsponge import set_global_units\n",
    "from mindsponge import Protein\n",
    "from mindsponge import DynamicUpdater\n",
    "from mindsponge.function import VelocityGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9397c0-5a6a-4338-9fa4-5b5ce46e0e58",
   "metadata": {},
   "source": [
    "## 单位设置\n",
    "\n",
    "这里我们提到的全局单位设置，主要是指输入输出的长度单位和能量单位，在MindSponge的计算过程中会自动根据默认单位进行计算，再将返回的结果转换成用户定义的单位。常用的长度单位是nm和A，一般在PDB文件里面是用A为单位。能量单位比较常用的是kJ/mol和kcal/mol。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bfe6a3-1f67-40ed-ba0d-33c0168c3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_units('nm', 'kj/mol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbf326-a968-4cf5-a405-1ba7c97576d6",
   "metadata": {},
   "source": [
    "## 蛋白质案例\n",
    "\n",
    "我们提供了一些简单的蛋白质案例以供测试，一般用pdb(Protein Data Bank)格式来存储蛋白质文件。下述案例就是一个不含H原子的pdb文件（该构象来自于MEGAProtein的预测结果）。\n",
    "\n",
    "![](docs/case2-1.png)\n",
    "\n",
    "在使用MindSponge构建Protein对象时，会自动为其在相对合理的位置补充H原子（如下图所示）。而这一过程之后，最好对其进行一次能量最小化的操作，以确保得到的构象中不会存在太多的冲突，比如两个原子距离太近等。\n",
    "\n",
    "![](docs/case2-3.png)\n",
    "\n",
    "如果使用常用的蛋白质可视化算法NewCartoon来展示的话，可以更清晰的看到这个构象中所存在的$\\alpha$螺旋和$\\beta$折叠等区域：\n",
    "\n",
    "![](docs/case2-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66371d6d-a10c-47ff-99fb-6568f64ccddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 H-Adding task complete.\n"
     ]
    }
   ],
   "source": [
    "pdb_name = 'case2.pdb'\n",
    "system = Protein(pdb=pdb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d313558-c263-4324-9a44-459dd2335de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = ForceField(system, 'AMBER.FF14SB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d85face-7806-4ee4-8f24-2889f073a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_opt = SteepestDescent(system.trainable_params(), 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ff76ae-4624-4fa4-92d3-e98d24638206",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = Sponge(system, energy, min_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d64e25-7d63-46e0-977a-b0626b1ed361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] KERNEL(21557,7ff8eca4f740,python):2022-08-15-14:33:46.265.785 [mindspore/ccsrc/plugin/device/gpu/kernel/cuda_impl/cuda_class/cuda_class_common.h:55] CalShapesSizeInBytes] For 'Neg', the shapes[0] is ( )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, E_pot: 141277.78, \n",
      "Step: 10, E_pot: 96736.516, \n",
      "Step: 20, E_pot: 75656.49, \n",
      "Step: 30, E_pot: 62071.25, \n",
      "Step: 40, E_pot: 52376.703, \n",
      "Step: 50, E_pot: 45027.336, \n",
      "Step: 60, E_pot: 39223.355, \n",
      "Step: 70, E_pot: 34505.496, \n",
      "Step: 80, E_pot: 30588.402, \n",
      "Step: 90, E_pot: 27282.945, \n",
      "Step: 100, E_pot: 24456.771, \n",
      "Step: 110, E_pot: 22013.08, \n",
      "Step: 120, E_pot: 19878.992, \n",
      "Step: 130, E_pot: 17998.312, \n",
      "Step: 140, E_pot: 16327.074, \n",
      "Step: 150, E_pot: 14830.457, \n",
      "Step: 160, E_pot: 13480.786, \n",
      "Step: 170, E_pot: 12255.753, \n",
      "Step: 180, E_pot: 11137.305, \n",
      "Step: 190, E_pot: 10110.746, \n",
      "Step: 200, E_pot: 9163.998, \n",
      "Step: 210, E_pot: 8287.03, \n",
      "Step: 220, E_pot: 7471.5605, \n",
      "Step: 230, E_pot: 6710.5723, \n",
      "Step: 240, E_pot: 5998.165, \n",
      "Step: 250, E_pot: 5329.3, \n",
      "Step: 260, E_pot: 4699.6875, \n",
      "Step: 270, E_pot: 4105.591, \n",
      "Step: 280, E_pot: 3543.8271, \n",
      "Step: 290, E_pot: 3011.5645, \n",
      "Step: 300, E_pot: 2506.3652, \n",
      "Step: 310, E_pot: 2026.0898, \n",
      "Step: 320, E_pot: 1568.8037, \n",
      "Step: 330, E_pot: 1132.8066, \n",
      "Step: 340, E_pot: 716.605, \n",
      "Step: 350, E_pot: 318.81982, \n",
      "Step: 360, E_pot: -61.800293, \n",
      "Step: 370, E_pot: -426.35645, \n",
      "Step: 380, E_pot: -775.85547, \n",
      "Step: 390, E_pot: -1111.2476, \n",
      "Step: 400, E_pot: -1433.3911, \n",
      "Step: 410, E_pot: -1743.0859, \n",
      "Step: 420, E_pot: -2041.0591, \n",
      "Step: 430, E_pot: -2328.0156, \n",
      "Step: 440, E_pot: -2604.5596, \n",
      "Step: 450, E_pot: -2871.316, \n",
      "Step: 460, E_pot: -3128.8188, \n",
      "Step: 470, E_pot: -3377.6152, \n",
      "Step: 480, E_pot: -3618.1797, \n",
      "Step: 490, E_pot: -3850.955, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mindsponge.core.sponge.Sponge at 0x7ff8229cbbd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_info = RunInfo(10)\n",
    "md.run(500, callbacks=[run_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6d410b-a152-4785-9a67-322996b09bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] KERNEL(21557,7ff8eca4f740,python):2022-08-15-14:34:11.351.015 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel_factory.cc:93] ReducePrecision] Kernel [StandardNormal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] PRE_ACT(21557,7ff8eca4f740,python):2022-08-15-14:34:11.352.206 [mindspore/ccsrc/plugin/device/gpu/optimizer/reduce_precision_fusion.cc:84] Run] Reduce precision for [StandardNormal] input 0\n"
     ]
    }
   ],
   "source": [
    "vgen = VelocityGenerator(300)\n",
    "velocity = vgen(system.coordinate.shape, system.atom_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4208b35-3d46-4b71-9144-f0e8d6959f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = DynamicUpdater(system,\n",
    "                     integrator=VelocityVerlet(system),\n",
    "                     thermostat=Langevin(system, 300),\n",
    "                     time_step=1e-3,\n",
    "                     velocity=velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a7bcba5-5ac0-4f46-94aa-f078f3e3ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = Sponge(system, energy, min_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf16e327-09fb-42dd-91ea-320b9acad87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_h5md = WriteH5MD(system, 'tutorial_b06.h5md', save_freq=10, write_velocity=True, write_force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1084b9b-4df7-46c0-8a34-ccb19df6a153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] KERNEL(21557,7ff8eca4f740,python):2022-08-15-14:34:17.508.028 [mindspore/ccsrc/plugin/device/gpu/kernel/gpu_kernel_factory.cc:93] ReducePrecision] Kernel [StandardNormal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] PRE_ACT(21557,7ff8eca4f740,python):2022-08-15-14:34:17.541.462 [mindspore/ccsrc/plugin/device/gpu/optimizer/reduce_precision_fusion.cc:84] Run] Reduce precision for [StandardNormal] input 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, E_pot: -4076.3867, E_kin: 9410.519, E_tot: 5334.132, Temperature: 298.4771\n",
      "Step: 10, E_pot: -3697.8032, E_kin: 7578.38, E_tot: 3880.5767, Temperature: 240.36646\n",
      "Step: 20, E_pot: -4086.9902, E_kin: 9538.316, E_tot: 5451.326, Temperature: 302.53052\n",
      "Step: 30, E_pot: -3298.1406, E_kin: 9015.568, E_tot: 5717.4277, Temperature: 285.95032\n",
      "Step: 40, E_pot: -4622.5137, E_kin: 10523.611, E_tot: 5901.0977, Temperature: 333.78152\n",
      "Step: 50, E_pot: -4311.3535, E_kin: 9763.19, E_tot: 5451.837, Temperature: 309.66296\n",
      "Step: 60, E_pot: -4552.1377, E_kin: 9773.1875, E_tot: 5221.05, Temperature: 309.98004\n",
      "Step: 70, E_pot: -4262.422, E_kin: 9748.969, E_tot: 5486.547, Temperature: 309.21188\n",
      "Step: 80, E_pot: -3947.5078, E_kin: 9759.893, E_tot: 5812.385, Temperature: 309.55835\n",
      "Step: 90, E_pot: -4503.5645, E_kin: 10081.858, E_tot: 5578.294, Temperature: 319.77026\n",
      "Step: 100, E_pot: -4601.1353, E_kin: 10137.48, E_tot: 5536.345, Temperature: 321.53445\n",
      "Step: 110, E_pot: -4396.6143, E_kin: 9751.86, E_tot: 5355.246, Temperature: 309.30362\n",
      "Step: 120, E_pot: -4574.443, E_kin: 10021.891, E_tot: 5447.4478, Temperature: 317.86826\n",
      "Step: 130, E_pot: -4452.721, E_kin: 9918.573, E_tot: 5465.852, Temperature: 314.5913\n",
      "Step: 140, E_pot: -4566.212, E_kin: 10153.604, E_tot: 5587.3916, Temperature: 322.04584\n",
      "Step: 150, E_pot: -4834.087, E_kin: 10374.283, E_tot: 5540.1963, Temperature: 329.04523\n",
      "Step: 160, E_pot: -4947.995, E_kin: 10472.8955, E_tot: 5524.9004, Temperature: 332.17297\n",
      "Step: 170, E_pot: -4593.0913, E_kin: 10067.248, E_tot: 5474.1567, Temperature: 319.3069\n",
      "Step: 180, E_pot: -4812.548, E_kin: 10190.713, E_tot: 5378.165, Temperature: 323.22284\n",
      "Step: 190, E_pot: -4902.0156, E_kin: 10408.461, E_tot: 5506.4453, Temperature: 330.12927\n",
      "Step: 200, E_pot: -4534.121, E_kin: 10208.251, E_tot: 5674.13, Temperature: 323.7791\n",
      "Step: 210, E_pot: -4702.8555, E_kin: 10173.033, E_tot: 5470.1777, Temperature: 322.6621\n",
      "Step: 220, E_pot: -4943.193, E_kin: 10239.435, E_tot: 5296.2417, Temperature: 324.7682\n",
      "Step: 230, E_pot: -4992.9976, E_kin: 10093.57, E_tot: 5100.5728, Temperature: 320.14175\n",
      "Step: 240, E_pot: -4977.7705, E_kin: 10111.828, E_tot: 5134.0576, Temperature: 320.72086\n",
      "Step: 250, E_pot: -4810.588, E_kin: 10133.996, E_tot: 5323.408, Temperature: 321.42395\n",
      "Step: 260, E_pot: -5009.32, E_kin: 10458.422, E_tot: 5449.102, Temperature: 331.71387\n",
      "Step: 270, E_pot: -5141.4194, E_kin: 10388.94, E_tot: 5247.521, Temperature: 329.5101\n",
      "Step: 280, E_pot: -5158.346, E_kin: 10367.768, E_tot: 5209.4214, Temperature: 328.83856\n",
      "Step: 290, E_pot: -5126.993, E_kin: 10248.885, E_tot: 5121.8916, Temperature: 325.06793\n",
      "Step: 300, E_pot: -4988.965, E_kin: 10255.332, E_tot: 5266.367, Temperature: 325.2724\n",
      "Step: 310, E_pot: -4878.6836, E_kin: 10224.91, E_tot: 5346.2266, Temperature: 324.30753\n",
      "Step: 320, E_pot: -5293.871, E_kin: 10549.183, E_tot: 5255.3115, Temperature: 334.5926\n",
      "Step: 330, E_pot: -5303.2017, E_kin: 10470.395, E_tot: 5167.193, Temperature: 332.09363\n",
      "Step: 340, E_pot: -5124.504, E_kin: 10182.535, E_tot: 5058.0312, Temperature: 322.96347\n",
      "Step: 350, E_pot: -4974.825, E_kin: 9997.469, E_tot: 5022.6436, Temperature: 317.09363\n",
      "Step: 360, E_pot: -5024.0967, E_kin: 10168.572, E_tot: 5144.4756, Temperature: 322.52063\n",
      "Step: 370, E_pot: -5028.2773, E_kin: 10299.788, E_tot: 5271.5107, Temperature: 326.68243\n",
      "Step: 380, E_pot: -5102.4395, E_kin: 10339.754, E_tot: 5237.3145, Temperature: 327.95007\n",
      "Step: 390, E_pot: -5134.4097, E_kin: 10227.01, E_tot: 5092.6, Temperature: 324.37408\n",
      "Step: 400, E_pot: -5266.518, E_kin: 10330.143, E_tot: 5063.6245, Temperature: 327.6452\n",
      "Step: 410, E_pot: -4785.3027, E_kin: 9945.83, E_tot: 5160.5273, Temperature: 315.4558\n",
      "Step: 420, E_pot: -4849.8, E_kin: 10065.031, E_tot: 5215.2314, Temperature: 319.23657\n",
      "Step: 430, E_pot: -4900.8354, E_kin: 10067.088, E_tot: 5166.2524, Temperature: 319.3018\n",
      "Step: 440, E_pot: -5205.8936, E_kin: 10271.573, E_tot: 5065.6797, Temperature: 325.78754\n",
      "Step: 450, E_pot: -5235.185, E_kin: 10234.097, E_tot: 4998.9116, Temperature: 324.59888\n",
      "Step: 460, E_pot: -5322.0625, E_kin: 10202.988, E_tot: 4880.926, Temperature: 323.61218\n",
      "Step: 470, E_pot: -5109.602, E_kin: 10223.681, E_tot: 5114.0786, Temperature: 324.26852\n",
      "Step: 480, E_pot: -5164.862, E_kin: 10301.824, E_tot: 5136.9624, Temperature: 326.747\n",
      "Step: 490, E_pot: -5245.6636, E_kin: 10284.302, E_tot: 5038.638, Temperature: 326.19125\n",
      "Step: 500, E_pot: -5249.575, E_kin: 10074.3545, E_tot: 4824.7793, Temperature: 319.53226\n",
      "Step: 510, E_pot: -5025.04, E_kin: 9935.213, E_tot: 4910.173, Temperature: 315.11908\n",
      "Step: 520, E_pot: -5245.932, E_kin: 10259.504, E_tot: 5013.572, Temperature: 325.40472\n",
      "Step: 530, E_pot: -5248.5146, E_kin: 10348.696, E_tot: 5100.1816, Temperature: 328.23367\n",
      "Step: 540, E_pot: -5385.1973, E_kin: 10343.092, E_tot: 4957.8945, Temperature: 328.05594\n",
      "Step: 550, E_pot: -5484.795, E_kin: 10258.088, E_tot: 4773.293, Temperature: 325.3598\n",
      "Step: 560, E_pot: -5469.743, E_kin: 10163.387, E_tot: 4693.6436, Temperature: 322.35614\n",
      "Step: 570, E_pot: -5257.5938, E_kin: 10102.371, E_tot: 4844.7773, Temperature: 320.42087\n",
      "Step: 580, E_pot: -5469.1284, E_kin: 10261.074, E_tot: 4791.946, Temperature: 325.45456\n",
      "Step: 590, E_pot: -5712.448, E_kin: 10496.6875, E_tot: 4784.2393, Temperature: 332.92758\n",
      "Step: 600, E_pot: -5268.8145, E_kin: 9925.377, E_tot: 4656.5625, Temperature: 314.8071\n",
      "Step: 610, E_pot: -5258.9062, E_kin: 9956.87, E_tot: 4697.964, Temperature: 315.806\n",
      "Step: 620, E_pot: -5370.957, E_kin: 10177.712, E_tot: 4806.755, Temperature: 322.8105\n",
      "Step: 630, E_pot: -5294.4717, E_kin: 10088.43, E_tot: 4793.958, Temperature: 319.9787\n",
      "Step: 640, E_pot: -5481.3677, E_kin: 10246.515, E_tot: 4765.147, Temperature: 324.99274\n",
      "Step: 650, E_pot: -5346.6445, E_kin: 9971.189, E_tot: 4624.545, Temperature: 316.26013\n",
      "Step: 660, E_pot: -5436.9834, E_kin: 10103.186, E_tot: 4666.202, Temperature: 320.44672\n",
      "Step: 670, E_pot: -5434.21, E_kin: 10155.984, E_tot: 4721.7744, Temperature: 322.12134\n",
      "Step: 680, E_pot: -5450.4546, E_kin: 10027.8955, E_tot: 4577.441, Temperature: 318.05872\n",
      "Step: 690, E_pot: -5548.757, E_kin: 10115.744, E_tot: 4566.9873, Temperature: 320.84503\n",
      "Step: 700, E_pot: -5519.098, E_kin: 10162.597, E_tot: 4643.4985, Temperature: 322.3311\n",
      "Step: 710, E_pot: -5597.6997, E_kin: 10190.386, E_tot: 4592.686, Temperature: 323.2125\n",
      "Step: 720, E_pot: -5605.233, E_kin: 10186.481, E_tot: 4581.2485, Temperature: 323.08865\n",
      "Step: 730, E_pot: -5565.158, E_kin: 10144.063, E_tot: 4578.9053, Temperature: 321.74326\n",
      "Step: 740, E_pot: -5682.679, E_kin: 10282.705, E_tot: 4600.026, Temperature: 326.1406\n",
      "Step: 750, E_pot: -5453.508, E_kin: 10069.291, E_tot: 4615.783, Temperature: 319.37167\n",
      "Step: 760, E_pot: -5417.2744, E_kin: 10061.104, E_tot: 4643.829, Temperature: 319.11197\n",
      "Step: 770, E_pot: -5592.138, E_kin: 10118.715, E_tot: 4526.5767, Temperature: 320.93927\n",
      "Step: 780, E_pot: -5571.0767, E_kin: 10085.949, E_tot: 4514.8726, Temperature: 319.90002\n",
      "Step: 790, E_pot: -5349.8154, E_kin: 9907.969, E_tot: 4558.1533, Temperature: 314.25494\n",
      "Step: 800, E_pot: -5573.4297, E_kin: 10141.967, E_tot: 4568.537, Temperature: 321.67676\n",
      "Step: 810, E_pot: -5601.605, E_kin: 10131.704, E_tot: 4530.099, Temperature: 321.35126\n",
      "Step: 820, E_pot: -5702.426, E_kin: 10237.951, E_tot: 4535.5254, Temperature: 324.72113\n",
      "Step: 830, E_pot: -5543.243, E_kin: 10111.236, E_tot: 4567.993, Temperature: 320.70206\n",
      "Step: 840, E_pot: -5665.7197, E_kin: 10277.415, E_tot: 4611.6953, Temperature: 325.9728\n",
      "Step: 850, E_pot: -5617.2534, E_kin: 10216.795, E_tot: 4599.5415, Temperature: 324.0501\n",
      "Step: 860, E_pot: -5632.573, E_kin: 10231.352, E_tot: 4598.7783, Temperature: 324.5118\n",
      "Step: 870, E_pot: -5465.728, E_kin: 9945.508, E_tot: 4479.78, Temperature: 315.4456\n",
      "Step: 880, E_pot: -5537.9717, E_kin: 10013.711, E_tot: 4475.7393, Temperature: 317.60883\n",
      "Step: 890, E_pot: -5456.0796, E_kin: 9970.023, E_tot: 4513.944, Temperature: 316.22314\n",
      "Step: 900, E_pot: -5535.903, E_kin: 10008.614, E_tot: 4472.7114, Temperature: 317.44714\n",
      "Step: 910, E_pot: -5480.838, E_kin: 9993.328, E_tot: 4512.49, Temperature: 316.96234\n",
      "Step: 920, E_pot: -5719.7227, E_kin: 10134.733, E_tot: 4415.0107, Temperature: 321.44733\n",
      "Step: 930, E_pot: -5641.464, E_kin: 10010.907, E_tot: 4369.4434, Temperature: 317.5199\n",
      "Step: 940, E_pot: -5583.4824, E_kin: 10047.311, E_tot: 4463.828, Temperature: 318.6745\n",
      "Step: 950, E_pot: -5715.5654, E_kin: 10182.935, E_tot: 4467.369, Temperature: 322.97617\n",
      "Step: 960, E_pot: -5707.426, E_kin: 10167.746, E_tot: 4460.3203, Temperature: 322.49442\n",
      "Step: 970, E_pot: -5606.245, E_kin: 10096.168, E_tot: 4489.923, Temperature: 320.22415\n",
      "Step: 980, E_pot: -5841.738, E_kin: 10267.094, E_tot: 4425.356, Temperature: 325.64548\n",
      "Step: 990, E_pot: -5575.398, E_kin: 9935.03, E_tot: 4359.6323, Temperature: 315.11328\n",
      "Step: 1000, E_pot: -5703.202, E_kin: 10064.758, E_tot: 4361.5557, Temperature: 319.22787\n",
      "Step: 1010, E_pot: -5889.102, E_kin: 10234.656, E_tot: 4345.554, Temperature: 324.61664\n",
      "Step: 1020, E_pot: -6005.488, E_kin: 10334.961, E_tot: 4329.473, Temperature: 327.79803\n",
      "Step: 1030, E_pot: -5990.4863, E_kin: 10247.381, E_tot: 4256.8945, Temperature: 325.0202\n",
      "Step: 1040, E_pot: -6215.8066, E_kin: 10576.243, E_tot: 4360.4365, Temperature: 335.45087\n",
      "Step: 1050, E_pot: -5928.621, E_kin: 10340.996, E_tot: 4412.375, Temperature: 327.98947\n",
      "Step: 1060, E_pot: -5953.8916, E_kin: 10308.845, E_tot: 4354.953, Temperature: 326.9697\n",
      "Step: 1070, E_pot: -5783.996, E_kin: 10202.489, E_tot: 4418.493, Temperature: 323.59637\n",
      "Step: 1080, E_pot: -5757.427, E_kin: 10078.986, E_tot: 4321.5596, Temperature: 319.67917\n",
      "Step: 1090, E_pot: -5698.4297, E_kin: 10106.701, E_tot: 4408.2715, Temperature: 320.55823\n",
      "Step: 1100, E_pot: -5835.2383, E_kin: 10212.314, E_tot: 4377.076, Temperature: 323.90802\n",
      "Step: 1110, E_pot: -5892.4004, E_kin: 10155.939, E_tot: 4263.539, Temperature: 322.11993\n",
      "Step: 1120, E_pot: -5776.423, E_kin: 10050.477, E_tot: 4274.0537, Temperature: 318.77493\n",
      "Step: 1130, E_pot: -5845.585, E_kin: 10097.504, E_tot: 4251.919, Temperature: 320.2665\n",
      "Step: 1140, E_pot: -5898.135, E_kin: 10125.175, E_tot: 4227.04, Temperature: 321.14417\n",
      "Step: 1150, E_pot: -6002.699, E_kin: 10196.99, E_tot: 4194.291, Temperature: 323.42197\n",
      "Step: 1160, E_pot: -5993.14, E_kin: 10139.281, E_tot: 4146.141, Temperature: 321.59158\n",
      "Step: 1170, E_pot: -5868.9897, E_kin: 10045.822, E_tot: 4176.8325, Temperature: 318.62732\n",
      "Step: 1180, E_pot: -5964.669, E_kin: 10174.156, E_tot: 4209.4873, Temperature: 322.69772\n",
      "Step: 1190, E_pot: -5874.041, E_kin: 10138.461, E_tot: 4264.42, Temperature: 321.56555\n",
      "Step: 1200, E_pot: -6108.864, E_kin: 10257.215, E_tot: 4148.351, Temperature: 325.33212\n",
      "Step: 1210, E_pot: -6096.3516, E_kin: 10100.463, E_tot: 4004.1113, Temperature: 320.36038\n",
      "Step: 1220, E_pot: -5950.573, E_kin: 9970.851, E_tot: 4020.2773, Temperature: 316.2494\n",
      "Step: 1230, E_pot: -5995.558, E_kin: 10147.311, E_tot: 4151.7524, Temperature: 321.84622\n",
      "Step: 1240, E_pot: -6168.427, E_kin: 10315.464, E_tot: 4147.037, Temperature: 327.17966\n",
      "Step: 1250, E_pot: -6040.095, E_kin: 10025.851, E_tot: 3985.7554, Temperature: 317.99384\n",
      "Step: 1260, E_pot: -6092.461, E_kin: 10091.258, E_tot: 3998.7969, Temperature: 320.0684\n",
      "Step: 1270, E_pot: -6022.173, E_kin: 9944.853, E_tot: 3922.6797, Temperature: 315.4248\n",
      "Step: 1280, E_pot: -6005.421, E_kin: 9992.115, E_tot: 3986.6943, Temperature: 316.92386\n",
      "Step: 1290, E_pot: -6102.508, E_kin: 10096.329, E_tot: 3993.8213, Temperature: 320.22925\n",
      "Step: 1300, E_pot: -6220.407, E_kin: 10131.707, E_tot: 3911.2998, Temperature: 321.35132\n",
      "Step: 1310, E_pot: -6006.385, E_kin: 9984.528, E_tot: 3978.1436, Temperature: 316.68323\n",
      "Step: 1320, E_pot: -6096.825, E_kin: 10051.896, E_tot: 3955.0713, Temperature: 318.81998\n",
      "Step: 1330, E_pot: -6089.19, E_kin: 10045.762, E_tot: 3956.5718, Temperature: 318.6254\n",
      "Step: 1340, E_pot: -6094.7593, E_kin: 10014.68, E_tot: 3919.9204, Temperature: 317.63953\n",
      "Step: 1350, E_pot: -5875.918, E_kin: 9795.219, E_tot: 3919.3008, Temperature: 310.6788\n",
      "Step: 1360, E_pot: -5766.835, E_kin: 9661.635, E_tot: 3894.7998, Temperature: 306.4419\n",
      "Step: 1370, E_pot: -5935.968, E_kin: 9794.76, E_tot: 3858.792, Temperature: 310.66428\n",
      "Step: 1380, E_pot: -5939.701, E_kin: 9832.178, E_tot: 3892.4766, Temperature: 311.85104\n",
      "Step: 1390, E_pot: -5939.793, E_kin: 9830.408, E_tot: 3890.6152, Temperature: 311.79492\n",
      "Step: 1400, E_pot: -5974.6895, E_kin: 9836.691, E_tot: 3862.002, Temperature: 311.99423\n",
      "Step: 1410, E_pot: -5814.4033, E_kin: 9714.355, E_tot: 3899.9521, Temperature: 308.11404\n",
      "Step: 1420, E_pot: -6094.5747, E_kin: 9995.363, E_tot: 3900.7886, Temperature: 317.0269\n",
      "Step: 1430, E_pot: -6247.5415, E_kin: 10061.746, E_tot: 3814.2046, Temperature: 319.13235\n",
      "Step: 1440, E_pot: -6342.367, E_kin: 10106.205, E_tot: 3763.838, Temperature: 320.54248\n",
      "Step: 1450, E_pot: -6260.9463, E_kin: 9905.233, E_tot: 3644.287, Temperature: 314.1682\n",
      "Step: 1460, E_pot: -6426.344, E_kin: 10111.669, E_tot: 3685.3247, Temperature: 320.7158\n",
      "Step: 1470, E_pot: -6126.8833, E_kin: 9841.267, E_tot: 3714.3833, Temperature: 312.1393\n",
      "Step: 1480, E_pot: -6035.089, E_kin: 9851.316, E_tot: 3816.2275, Temperature: 312.45807\n",
      "Step: 1490, E_pot: -6278.3657, E_kin: 9997.67, E_tot: 3719.3042, Temperature: 317.10004\n",
      "Step: 1500, E_pot: -6101.3965, E_kin: 9808.215, E_tot: 3706.8184, Temperature: 311.091\n",
      "Step: 1510, E_pot: -6218.3086, E_kin: 9818.92, E_tot: 3600.6113, Temperature: 311.43054\n",
      "Step: 1520, E_pot: -6137.569, E_kin: 9845.438, E_tot: 3707.8696, Temperature: 312.27167\n",
      "Step: 1530, E_pot: -6151.9976, E_kin: 9847.9, E_tot: 3695.9028, Temperature: 312.34973\n",
      "Step: 1540, E_pot: -6307.1064, E_kin: 10035.458, E_tot: 3728.3516, Temperature: 318.29858\n",
      "Step: 1550, E_pot: -6448.3975, E_kin: 10079.961, E_tot: 3631.5635, Temperature: 319.71008\n",
      "Step: 1560, E_pot: -6495.8105, E_kin: 9955.469, E_tot: 3459.6582, Temperature: 315.76154\n",
      "Step: 1570, E_pot: -6365.508, E_kin: 9907.21, E_tot: 3541.7021, Temperature: 314.2309\n",
      "Step: 1580, E_pot: -6349.185, E_kin: 9911.121, E_tot: 3561.936, Temperature: 314.35495\n",
      "Step: 1590, E_pot: -6265.538, E_kin: 9855.336, E_tot: 3589.7979, Temperature: 312.58557\n",
      "Step: 1600, E_pot: -6407.036, E_kin: 9896.853, E_tot: 3489.8164, Temperature: 313.90237\n",
      "Step: 1610, E_pot: -6572.0205, E_kin: 9980.994, E_tot: 3408.9736, Temperature: 316.57114\n",
      "Step: 1620, E_pot: -6548.9385, E_kin: 10003.822, E_tot: 3454.8838, Temperature: 317.29517\n",
      "Step: 1630, E_pot: -6549.778, E_kin: 10001.47, E_tot: 3451.692, Temperature: 317.22055\n",
      "Step: 1640, E_pot: -6535.3643, E_kin: 9963.717, E_tot: 3428.3525, Temperature: 316.02313\n",
      "Step: 1650, E_pot: -6366.4717, E_kin: 9760.036, E_tot: 3393.5645, Temperature: 309.56293\n",
      "Step: 1660, E_pot: -6384.057, E_kin: 9784.139, E_tot: 3400.0815, Temperature: 310.3274\n",
      "Step: 1670, E_pot: -6591.284, E_kin: 9998.986, E_tot: 3407.7021, Temperature: 317.14178\n",
      "Step: 1680, E_pot: -6507.2246, E_kin: 9895.669, E_tot: 3388.4443, Temperature: 313.8648\n",
      "Step: 1690, E_pot: -6576.992, E_kin: 9987.629, E_tot: 3410.6367, Temperature: 316.7816\n",
      "Step: 1700, E_pot: -6450.0503, E_kin: 9832.656, E_tot: 3382.606, Temperature: 311.86624\n",
      "Step: 1710, E_pot: -6360.859, E_kin: 9700.926, E_tot: 3340.067, Temperature: 307.68808\n",
      "Step: 1720, E_pot: -6390.17, E_kin: 9812.27, E_tot: 3422.0996, Temperature: 311.21964\n",
      "Step: 1730, E_pot: -6532.209, E_kin: 9867.609, E_tot: 3335.4004, Temperature: 312.97485\n",
      "Step: 1740, E_pot: -6539.23, E_kin: 9889.371, E_tot: 3350.141, Temperature: 313.66507\n",
      "Step: 1750, E_pot: -6606.774, E_kin: 9943.695, E_tot: 3336.9214, Temperature: 315.3881\n",
      "Step: 1760, E_pot: -6575.6133, E_kin: 10002.355, E_tot: 3426.7422, Temperature: 317.24866\n",
      "Step: 1770, E_pot: -6542.6143, E_kin: 9882.332, E_tot: 3339.7178, Temperature: 313.44183\n",
      "Step: 1780, E_pot: -6580.205, E_kin: 10008.177, E_tot: 3427.9717, Temperature: 317.4333\n",
      "Step: 1790, E_pot: -6443.7812, E_kin: 9765.943, E_tot: 3322.162, Temperature: 309.75027\n",
      "Step: 1800, E_pot: -6421.782, E_kin: 9713.274, E_tot: 3291.4922, Temperature: 308.07974\n",
      "Step: 1810, E_pot: -6471.0146, E_kin: 9837.15, E_tot: 3366.1357, Temperature: 312.00876\n",
      "Step: 1820, E_pot: -6375.472, E_kin: 9779.196, E_tot: 3403.724, Temperature: 310.17062\n",
      "Step: 1830, E_pot: -6436.3887, E_kin: 9753.817, E_tot: 3317.4287, Temperature: 309.36566\n",
      "Step: 1840, E_pot: -6562.213, E_kin: 9850.719, E_tot: 3288.5059, Temperature: 312.43912\n",
      "Step: 1850, E_pot: -6526.1025, E_kin: 9854.98, E_tot: 3328.878, Temperature: 312.57428\n",
      "Step: 1860, E_pot: -6450.585, E_kin: 9856.5, E_tot: 3405.915, Temperature: 312.6225\n",
      "Step: 1870, E_pot: -6413.2183, E_kin: 9868.771, E_tot: 3455.5532, Temperature: 313.01172\n",
      "Step: 1880, E_pot: -6579.624, E_kin: 9968.165, E_tot: 3388.541, Temperature: 316.1642\n",
      "Step: 1890, E_pot: -6427.2954, E_kin: 9824.006, E_tot: 3396.7104, Temperature: 311.59186\n",
      "Step: 1900, E_pot: -6451.613, E_kin: 9786.594, E_tot: 3334.981, Temperature: 310.40524\n",
      "Step: 1910, E_pot: -6460.4414, E_kin: 9887.205, E_tot: 3426.7637, Temperature: 313.5964\n",
      "Step: 1920, E_pot: -6097.927, E_kin: 9566.728, E_tot: 3468.8008, Temperature: 303.43167\n",
      "Step: 1930, E_pot: -6335.302, E_kin: 9816.711, E_tot: 3481.4092, Temperature: 311.3605\n",
      "Step: 1940, E_pot: -6477.3896, E_kin: 9910.428, E_tot: 3433.038, Temperature: 314.33295\n",
      "Step: 1950, E_pot: -6604.278, E_kin: 9981.949, E_tot: 3377.6714, Temperature: 316.6014\n",
      "Step: 1960, E_pot: -6493.423, E_kin: 9855.766, E_tot: 3362.3428, Temperature: 312.5992\n",
      "Step: 1970, E_pot: -6468.45, E_kin: 9910.179, E_tot: 3441.7285, Temperature: 314.32504\n",
      "Step: 1980, E_pot: -6495.069, E_kin: 10003.406, E_tot: 3508.3374, Temperature: 317.28198\n",
      "Step: 1990, E_pot: -6475.7715, E_kin: 9989.205, E_tot: 3513.4336, Temperature: 316.83154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mindsponge.core.sponge.Sponge at 0x7ff7d05eb7d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.change_optimizer(opt)\n",
    "md.run(2000, callbacks=[run_info, cb_h5md])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
